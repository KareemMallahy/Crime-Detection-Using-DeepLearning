{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d1c4f67c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#Importing Libries\n",
    "import os\n",
    "import zipfile\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import imageio as iio\n",
    "from matplotlib.image import imread\n",
    "import cv2\n",
    "import nibabel as nib\n",
    "from scipy import ndimage\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.layers import Conv3D, MaxPool3D, Flatten, Dense\n",
    "from tensorflow.keras.layers import Dropout, Input, BatchNormalization\n",
    "from tensorflow.keras.losses import categorical_crossentropy\n",
    "from tensorflow.keras.optimizers import Adadelta\n",
    "from matplotlib.pyplot import cm\n",
    "from tensorflow.keras.models import Model\n",
    "import numpy as np\n",
    "import keras\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.utils import normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f9b2b10b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n"
     ]
    }
   ],
   "source": [
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e382656d",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_folder = '/Users/kareemel-mallahy/Desktop/Graduation Project/DataSetFrames/Train/logs'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "532f89a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "78e57851",
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf /logs/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fdbe8470",
   "metadata": {},
   "outputs": [],
   "source": [
    "rm -rf logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bab84971",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "log_folder = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e47236fd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "27e6b60a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define location of dataset\n",
    "directory = \"/Users/kareemel-mallahy/Desktop/Graduation Project/DataSetFrames/Train\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d46f37b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading Data\n",
    "anomly_scan_path = []\n",
    "count = 0 \n",
    "Anomly_Scan = []\n",
    "label = []\n",
    "directory = \"/Users/kareemel-mallahy/Desktop/Graduation Project/DataSetFrames/Train\"\n",
    "count = 0\n",
    "for j in os.listdir(directory):\n",
    "    if count == 1:\n",
    "        break\n",
    "    count += 1\n",
    "    if not j.startswith('.'):\n",
    "        directory = directory + '/' + j\n",
    "        for y in os.listdir(directory):\n",
    "            if not y.startswith('.'):\n",
    "                Newdirectory = directory + '/' + y\n",
    "                image = cv2.imread(Newdirectory)\n",
    "                Anomly_Scan.append(image)\n",
    "\n",
    "        \n",
    "    directory = \"/Users/kareemel-mallahy/Desktop/Graduation Project/DataSetFrames/Train\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8bb1183b",
   "metadata": {},
   "outputs": [],
   "source": [
    "AnomlyTrainAndVal = np.array(Anomly_Scan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e933414b",
   "metadata": {},
   "outputs": [],
   "source": [
    "del Anomly_Scan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c8546601",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'\n",
    "directory = '/Users/kareemel-mallahy/Desktop/Graduation Project/NormalVideos'\n",
    "normal_scan_path = []\n",
    "count = 0\n",
    "\n",
    "for x in os.listdir(directory):\n",
    "    if count >= 10000:\n",
    "        break\n",
    "    \n",
    "    newDirc = directory + '/' + x\n",
    "    image = cv2.imread(newDirc)\n",
    "    normal_scan_path.append(image)\n",
    "    count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "af48e760",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000\n"
     ]
    }
   ],
   "source": [
    "print(len(normal_scan_path))\n",
    "NormalTrainAndVal = np.array(normal_scan_path)\n",
    "del normal_scan_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c44754fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'print(AnomlyTrainAndVal.shape)\\nprint(NormalTrainAndVal.shape)\\nAnomlyTrainAndVal = normalize(AnomlyTrainAndVal,axis = 1)\\nprint(AnomlyTrainAndVal.shape)\\n\\nNormalTrainAndVal = normalize(NormalTrainAndVal,axis = 1)\\nprint(NormalTrainAndVal.shape)'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"print(AnomlyTrainAndVal.shape)\n",
    "print(NormalTrainAndVal.shape)\n",
    "AnomlyTrainAndVal = normalize(AnomlyTrainAndVal,axis = 1)\n",
    "print(AnomlyTrainAndVal.shape)\n",
    "\n",
    "NormalTrainAndVal = normalize(NormalTrainAndVal,axis = 1)\n",
    "print(NormalTrainAndVal.shape)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b96e0e25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For the CT scans having presence of viral pneumonia\n",
    "# assign 1, for the normal ones assign 0.\n",
    "abnormal_labels = np.array([1 for _ in range(len(AnomlyTrainAndVal))])\n",
    "normal_labels = np.array([0 for _ in range(len(NormalTrainAndVal))])\n",
    "\n",
    "#x_train = x_train[0:5 , : , : , :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5d7e3273",
   "metadata": {},
   "outputs": [],
   "source": [
    "POSITIVE_CLASS = 1\n",
    "BAG_COUNT = 25\n",
    "VAL_BAG_COUNT = 22\n",
    "BAG_SIZE = 100\n",
    "PLOT_SIZE = 100\n",
    "ENSEMBLE_AVG_COUNT = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4c813c2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating Bags (MIL)\n",
    "def Bags(data, labels, positiveClass, NumberOfInstaces):\n",
    "    Allbags = []\n",
    "    bag_labels = []\n",
    "    \n",
    "    counter = 0\n",
    "    count = 0\n",
    "    \n",
    "    x = True\n",
    "    \n",
    "    while x:\n",
    "        label = 0\n",
    "        bags = []\n",
    "        for w in range (0, NumberOfInstaces):\n",
    "            bags.append(data[counter])\n",
    "            \n",
    "            if labels[counter] == 1:\n",
    "                label = positiveClass\n",
    "            \n",
    "            counter += 1\n",
    "\n",
    "        count += NumberOfInstaces\n",
    "        bags = np.array(bags)\n",
    "        Allbags.append(bags)\n",
    "        bag_labels.append(label)\n",
    "        if(len(data) - count >= NumberOfInstaces):\n",
    "            x = True\n",
    "        else:\n",
    "            x = False\n",
    "    \n",
    "    return Allbags, bag_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "35b5c104",
   "metadata": {},
   "outputs": [],
   "source": [
    "anomlyVid, anomlyLab = Bags(AnomlyTrainAndVal, abnormal_labels, 1, 400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "624aa272",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "58\n",
      "58\n"
     ]
    }
   ],
   "source": [
    "anomlyVidTrain = np.array(anomlyVid)\n",
    "anomlyLabTrain = np.array(anomlyLab)\n",
    "print(len(anomlyVid))\n",
    "print(len(anomlyLab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "11c09c43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(58, 400, 64, 64, 3)\n",
      "(58, 400, 64, 64, 3)\n"
     ]
    }
   ],
   "source": [
    "print(anomlyVidTrain.shape)\n",
    "print(anomlyVidTrain.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "604a0a37",
   "metadata": {},
   "outputs": [],
   "source": [
    "del AnomlyTrainAndVal, abnormal_labels, anomlyVid, anomlyLab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "34117aca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_train: (58, 400, 64, 64, 3)\n",
      "Shape of Bag: (400, 64, 64, 3)\n",
      "Shape of Frame: (64, 64, 3)\n"
     ]
    }
   ],
   "source": [
    "print(\"Shape of X_train:\", anomlyVidTrain.shape)\n",
    "print(\"Shape of Bag:\", anomlyVidTrain[0].shape)\n",
    "print(\"Shape of Frame:\", anomlyVidTrain[0][0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5fc11bb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "NormalVid, normalLab = Bags(NormalTrainAndVal, normal_labels, 1, 400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bc4bf04a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25\n",
      "25\n"
     ]
    }
   ],
   "source": [
    "NormalVidTrain = np.array(NormalVid)\n",
    "normalLabTrain = np.array(normalLab)\n",
    "print(len(NormalVid))\n",
    "print(len(normalLab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "579520e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25, 400, 64, 64, 3)\n",
      "(25,)\n"
     ]
    }
   ],
   "source": [
    "print(NormalVidTrain.shape)\n",
    "print(normalLabTrain.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e6333e1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "del NormalTrainAndVal, normal_labels, NormalVid, normalLab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1cc11291",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'\n",
    "x_val = np.concatenate((anomlyVidTrain[:10], NormalVidTrain[:10]), axis=0)\n",
    "y_val = np.concatenate((anomlyLabTrain[:10], normalLabTrain[:10]), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9fc30d60",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'\n",
    "x_train = np.concatenate((anomlyVidTrain[10:], NormalVidTrain[10:]), axis=0)\n",
    "y_train = np.concatenate((anomlyLabTrain[10:], normalLabTrain[10:]), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "472b339b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63\n",
      "63\n",
      "20\n",
      "20\n"
     ]
    }
   ],
   "source": [
    "print(len(x_train))\n",
    "print(len(y_train))\n",
    "print(len(x_val))\n",
    "print(len(y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e166ba8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "del anomlyVidTrain, NormalVidTrain, anomlyLabTrain, normalLabTrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6b2a5fea",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = tf.keras.utils.to_categorical(\n",
    "    y_train, num_classes=2, dtype='float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a31c4c29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 1.]\n",
      "[0. 1.]\n",
      "[0. 1.]\n",
      "[0. 1.]\n",
      "[0. 1.]\n",
      "[0. 1.]\n",
      "[0. 1.]\n",
      "[0. 1.]\n",
      "[0. 1.]\n",
      "[0. 1.]\n",
      "[0. 1.]\n",
      "[0. 1.]\n",
      "[0. 1.]\n",
      "[0. 1.]\n",
      "[0. 1.]\n",
      "[0. 1.]\n",
      "[0. 1.]\n",
      "[0. 1.]\n",
      "[0. 1.]\n",
      "[0. 1.]\n",
      "[0. 1.]\n",
      "[0. 1.]\n",
      "[0. 1.]\n",
      "[0. 1.]\n",
      "[0. 1.]\n",
      "[0. 1.]\n",
      "[0. 1.]\n",
      "[0. 1.]\n",
      "[0. 1.]\n",
      "[0. 1.]\n",
      "[0. 1.]\n",
      "[0. 1.]\n",
      "[0. 1.]\n",
      "[0. 1.]\n",
      "[0. 1.]\n",
      "[0. 1.]\n",
      "[0. 1.]\n",
      "[0. 1.]\n",
      "[0. 1.]\n",
      "[0. 1.]\n",
      "[0. 1.]\n",
      "[0. 1.]\n",
      "[0. 1.]\n",
      "[0. 1.]\n",
      "[0. 1.]\n",
      "[0. 1.]\n",
      "[0. 1.]\n",
      "[0. 1.]\n",
      "[1. 0.]\n",
      "[1. 0.]\n",
      "[1. 0.]\n",
      "[1. 0.]\n",
      "[1. 0.]\n",
      "[1. 0.]\n",
      "[1. 0.]\n",
      "[1. 0.]\n",
      "[1. 0.]\n",
      "[1. 0.]\n",
      "[1. 0.]\n",
      "[1. 0.]\n",
      "[1. 0.]\n",
      "[1. 0.]\n",
      "[1. 0.]\n"
     ]
    }
   ],
   "source": [
    "for i in range (0, len(y_train)):\n",
    "    print(y_train[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e9a20e2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_val = tf.keras.utils.to_categorical(\n",
    "    y_val, num_classes=2, dtype='float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "72b64ab4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]]\n"
     ]
    }
   ],
   "source": [
    "print(y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "04bf5706",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(63, 400, 64, 64, 3)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a56a5132",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation, Flatten, Reshape\n",
    "from keras.layers.convolutional import Conv3D, MaxPooling3D,Conv2D,AveragePooling2D,AveragePooling3D\n",
    "from keras.layers import Dense, GlobalAveragePooling3D,GlobalAveragePooling2D\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, LearningRateScheduler,ReduceLROnPlateau\n",
    "from keras.optimizers import SGD, RMSprop, Adadelta\n",
    "from keras.utils import np_utils, generic_utils\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.convolutional_recurrent import ConvLSTM2D\n",
    "\n",
    "# Define model\n",
    "weight_decay = 0.00005\n",
    "l2=keras.regularizers.l2\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv3D(2,(3,3,3),\n",
    "                        input_shape=(400, 64, 64, 3),\n",
    "                        activation='relu'))\n",
    "model.add(Conv3D(4,(3,3,3), strides=(1,1,1),padding='same', \n",
    "                    dilation_rate=(1,1,1), kernel_initializer='he_normal',\n",
    "                    kernel_regularizer=l2(weight_decay), use_bias=False, \n",
    "                    name='Conv3D_2a_a', activation = 'relu'))\n",
    "model.add(MaxPooling3D(pool_size=(2,2,2)))\n",
    "\n",
    "\n",
    "model.add(Conv3D(8,(3,3,3), strides=(1,1,1),padding='same', \n",
    "                    dilation_rate=(1,1,1), kernel_initializer='he_normal',\n",
    "                    kernel_regularizer=l2(weight_decay), use_bias=False, \n",
    "                    name='Conv3D_2b_a', activation = 'relu'))\n",
    "model.add(Conv3D(16,(3,3,3), strides=(1,1,1),padding='same', \n",
    "                    dilation_rate=(1,1,1), kernel_initializer='he_normal',\n",
    "                    kernel_regularizer=l2(weight_decay), use_bias=False, \n",
    "                    name='Conv3D_2b_b', activation = 'relu'))\n",
    "model.add(MaxPooling3D(pool_size=(2, 2,2)))\n",
    "\n",
    "\n",
    "model.add(Conv3D(32,(3,3,3), strides=(1,1,1),padding='same', \n",
    "                    dilation_rate=(1,1,1), kernel_initializer='he_normal',\n",
    "                    kernel_regularizer=l2(weight_decay), use_bias=False, \n",
    "                    name='Conv3D_2c_a', activation = 'relu'))\n",
    "model.add(Conv3D(64,(3,3,3), strides=(1,1,1),padding='same', \n",
    "                    dilation_rate=(1,1,1), kernel_initializer='he_normal',\n",
    "                    kernel_regularizer=l2(weight_decay), use_bias=False, \n",
    "                    name='Conv3D_2c_b', activation = 'relu'))\n",
    "model.add(MaxPooling3D(pool_size=(2, 2,2)))\n",
    "\n",
    "\n",
    "model.add(ConvLSTM2D(filters=64, kernel_size=(3,3),\n",
    "                  strides=(1,1),padding='same',\n",
    "                      kernel_initializer='he_normal', recurrent_initializer='he_normal',\n",
    "                      kernel_regularizer=l2(weight_decay), recurrent_regularizer=l2(weight_decay),\n",
    "                      return_sequences=True, name='gatedclstm2d_2'))\n",
    "\n",
    "model.add(ConvLSTM2D(filters=64, kernel_size=(3,3),\n",
    "                  strides=(1,1),padding='same',\n",
    "                      kernel_initializer='he_normal', recurrent_initializer='he_normal',\n",
    "                      kernel_regularizer=l2(weight_decay), recurrent_regularizer=l2(weight_decay),\n",
    "                      return_sequences=True, name='gatedclstm2d_3'))\n",
    "\n",
    "\n",
    "#model.add(MaxPooling3D(pool_size=(nb_pool[0], nb_pool[0], nb_pool[0])))\n",
    "#model.add(Flatten())\n",
    "model.add(GlobalAveragePooling3D())\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(2,kernel_initializer='normal'))\n",
    "\n",
    "model.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "79daf398",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv3d_1 (Conv3D)            (None, 398, 62, 62, 2)    164       \n",
      "_________________________________________________________________\n",
      "Conv3D_2a_a (Conv3D)         (None, 398, 62, 62, 4)    216       \n",
      "_________________________________________________________________\n",
      "max_pooling3d_1 (MaxPooling3 (None, 199, 31, 31, 4)    0         \n",
      "_________________________________________________________________\n",
      "Conv3D_2b_a (Conv3D)         (None, 199, 31, 31, 8)    864       \n",
      "_________________________________________________________________\n",
      "Conv3D_2b_b (Conv3D)         (None, 199, 31, 31, 16)   3456      \n",
      "_________________________________________________________________\n",
      "max_pooling3d_2 (MaxPooling3 (None, 99, 15, 15, 16)    0         \n",
      "_________________________________________________________________\n",
      "Conv3D_2c_a (Conv3D)         (None, 99, 15, 15, 32)    13824     \n",
      "_________________________________________________________________\n",
      "Conv3D_2c_b (Conv3D)         (None, 99, 15, 15, 64)    55296     \n",
      "_________________________________________________________________\n",
      "max_pooling3d_3 (MaxPooling3 (None, 49, 7, 7, 64)      0         \n",
      "_________________________________________________________________\n",
      "gatedclstm2d_2 (ConvLSTM2D)  (None, 49, 7, 7, 64)      295168    \n",
      "_________________________________________________________________\n",
      "gatedclstm2d_3 (ConvLSTM2D)  (None, 49, 7, 7, 64)      295168    \n",
      "_________________________________________________________________\n",
      "global_average_pooling3d_1 ( (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 2)                 130       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 2)                 0         \n",
      "=================================================================\n",
      "Total params: 664,286\n",
      "Trainable params: 664,286\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "077c885e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "\n",
    "checkpoint_ACC = ModelCheckpoint(\"/Users/kareemel-mallahy/Desktop/Graduation Project/Models/SDGModelLSTM_2_Acc_3.h5\", monitor='acc',save_best_only=True, verbose=1, mode='auto')\n",
    "checkpoint_Val_ACC = ModelCheckpoint(\"/Users/kareemel-mallahy/Desktop/Graduation Project/Models/SDGModelLSTM_2_Val_Acc_3.h5\", monitor='val_acc',save_best_only=True, verbose=1, mode='auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "c0118f40",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_folder = 'logs'\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "callbacks = [TensorBoard(log_dir=log_folder,\n",
    "                         histogram_freq=1,\n",
    "                         write_graph=True,\n",
    "                         write_images=True,\n",
    "                         update_freq='epoch',\n",
    "                         profile_batch=2,\n",
    "                         embeddings_freq=1)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "411b43ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 63 samples, validate on 20 samples\n",
      "Epoch 1/90\n",
      "63/63 [==============================] - 144s 2s/step - loss: 0.7549 - acc: 0.7619 - val_loss: 0.8315 - val_acc: 0.5000\n",
      "Epoch 2/90\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-32-9f9368600b24>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"binary_crossentropy\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'acc'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m model.fit(x_train,y_train,batch_size=10,\n\u001b[0;32m---> 15\u001b[0;31m           validation_data=(x_val, y_val), epochs=90)\n\u001b[0m",
      "\u001b[0;32m~/.conda/envs/GraduationProject_CrimeDetection/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m   1237\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1238\u001b[0m                                         \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1239\u001b[0;31m                                         validation_freq=validation_freq)\n\u001b[0m\u001b[1;32m   1240\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1241\u001b[0m     def evaluate(self,\n",
      "\u001b[0;32m~/.conda/envs/GraduationProject_CrimeDetection/lib/python3.6/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, fit_function, fit_inputs, out_labels, batch_size, epochs, verbose, callbacks, val_function, val_inputs, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq)\u001b[0m\n\u001b[1;32m    194\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 196\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfit_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    197\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/GraduationProject_CrimeDetection/lib/python3.6/site-packages/tensorflow_core/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3738\u001b[0m         \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmath_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3739\u001b[0m       \u001b[0mconverted_inputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3740\u001b[0;31m     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mconverted_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3741\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3742\u001b[0m     \u001b[0;31m# EagerTensor.numpy() will often make a copy to ensure memory safety.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/GraduationProject_CrimeDetection/lib/python3.6/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1079\u001b[0m       \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mFor\u001b[0m \u001b[0minvalid\u001b[0m \u001b[0mpositional\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mkeyword\u001b[0m \u001b[0margument\u001b[0m \u001b[0mcombinations\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1080\u001b[0m     \"\"\"\n\u001b[0;32m-> 1081\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1082\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1083\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/GraduationProject_CrimeDetection/lib/python3.6/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1119\u001b[0m       raise TypeError(\"Keyword arguments {} unknown. Expected {}.\".format(\n\u001b[1;32m   1120\u001b[0m           list(kwargs.keys()), list(self._arg_keywords)))\n\u001b[0;32m-> 1121\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1123\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/GraduationProject_CrimeDetection/lib/python3.6/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1222\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1223\u001b[0m       flat_outputs = forward_function.call(\n\u001b[0;32m-> 1224\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager)\n\u001b[0m\u001b[1;32m   1225\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1226\u001b[0m       \u001b[0mgradient_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_delayed_rewrite_functions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregister\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/GraduationProject_CrimeDetection/lib/python3.6/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    509\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    510\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"executor_type\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexecutor_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"config_proto\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 511\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    512\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    513\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m~/.conda/envs/GraduationProject_CrimeDetection/lib/python3.6/site-packages/tensorflow_core/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tensorflow.TFE_Py_Execute(ctx._handle, device_name,\n\u001b[1;32m     60\u001b[0m                                                \u001b[0mop_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m                                                num_outputs)\n\u001b[0m\u001b[1;32m     62\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\"\"\"# Train the model, doing validation at the end of each epoch\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "epochs = 20\n",
    "print(x_train.shape)\n",
    "model = tf.keras.models.load_model('/Users/kareemel-mallahy/Desktop/Graduation Project/Models/SDGModelLSTM_1_Acc_3.h5')\"\"\"\n",
    "from tensorflow.python.keras.callbacks import TensorBoard\n",
    "lr_schedule = keras.optimizers.schedules.ExponentialDecay(\n",
    "    initial_learning_rate=1e-2,\n",
    "    decay_steps=10000,\n",
    "    decay_rate=0.9)\n",
    "optimizer = keras.optimizers.SGD(learning_rate=lr_schedule)\n",
    "model.compile(loss=\"binary_crossentropy\", optimizer=optimizer, metrics=['acc'])\n",
    "model.fit(x_train,y_train,batch_size=10,\n",
    "          validation_data=(x_val, y_val), epochs=90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71878cc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "http://localhost:6006"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b2aaed7",
   "metadata": {},
   "outputs": [],
   "source": [
    "%tensorboard -- logdir={log}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f97bdb86",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.load_model('/Users/kareemel-mallahy/Desktop/Graduation Project/Models/3DCNN-LSTM-BestPrediction.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "0f8de7da",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = []\n",
    "labels = []\n",
    "\n",
    "path = '/Users/kareemel-mallahy/Desktop/Graduation Project/DataSetFrames/Test/Arrest'\n",
    "for x in os.listdir(path):\n",
    "    test.append(cv2.imread(path + '/' + x))\n",
    "    labels.append(1)\n",
    "    \n",
    "path = '/Users/kareemel-mallahy/Desktop/Graduation Project/DataSetFrames/Test/Arson'\n",
    "for x in os.listdir(path):\n",
    "    test.append(cv2.imread(path + '/' + x))\n",
    "    labels.append(1)\n",
    "    \n",
    "path = '/Users/kareemel-mallahy/Desktop/Graduation Project/DataSetFrames/Test/Assault'\n",
    "for x in os.listdir(path):\n",
    "    test.append(cv2.imread(path + '/' + x))\n",
    "    labels.append(1)\n",
    "        \n",
    "path = '/Users/kareemel-mallahy/Desktop/Graduation Project/DataSetFrames/Test/Burglary'\n",
    "for x in os.listdir(path):\n",
    "    test.append(cv2.imread(path + '/' + x))\n",
    "    labels.append(1)\n",
    "        \n",
    "path = '/Users/kareemel-mallahy/Desktop/Graduation Project/DataSetFrames/Test/Explosion'\n",
    "for x in os.listdir(path):\n",
    "    test.append(cv2.imread(path + '/' + x))\n",
    "    labels.append(1)\n",
    "    \n",
    "path = '/Users/kareemel-mallahy/Desktop/Graduation Project/DataSetFrames/Test/Fighting'\n",
    "for x in os.listdir(path):\n",
    "    test.append(cv2.imread(path + '/' + x))\n",
    "    labels.append(1)\n",
    "    \n",
    "path = '/Users/kareemel-mallahy/Desktop/Graduation Project/DataSetFrames/Test/RoadAccidents'\n",
    "for x in os.listdir(path):\n",
    "    test.append(cv2.imread(path + '/' + x))\n",
    "    labels.append(1)\n",
    "    \n",
    "path = '/Users/kareemel-mallahy/Desktop/Graduation Project/DataSetFrames/Test/Robbery'\n",
    "for x in os.listdir(path):\n",
    "    test.append(cv2.imread(path + '/' + x))\n",
    "    labels.append(1)\n",
    "path = '/Users/kareemel-mallahy/Desktop/Graduation Project/DataSetFrames/Test/Shooting'\n",
    "for x in os.listdir(path):\n",
    "    test.append(cv2.imread(path + '/' + x))\n",
    "    labels.append(1)\n",
    "path = '/Users/kareemel-mallahy/Desktop/Graduation Project/DataSetFrames/Test/Shoplifting'\n",
    "for x in os.listdir(path):\n",
    "    test.append(cv2.imread(path + '/' + x))\n",
    "    labels.append(1)\n",
    "path = '/Users/kareemel-mallahy/Desktop/Graduation Project/DataSetFrames/Test/Stealing'\n",
    "for x in os.listdir(path):\n",
    "    test.append(cv2.imread(path + '/' + x))\n",
    "    labels.append(1)\n",
    "    \n",
    "path = '/Users/kareemel-mallahy/Desktop/Graduation Project/DataSetFrames/Test/Vandalism'\n",
    "for x in os.listdir(path):\n",
    "    test.append(cv2.imread(path + '/' + x))\n",
    "    labels.append(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "4e0bfa17",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-38-8a8a96d5a395>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mcount\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mtest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'/'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "path = '/Users/kareemel-mallahy/Desktop/Graduation Project/DataSetFrames/Test/NormalVideos'\n",
    "count = 0\n",
    "for x in os.listdir(path):\n",
    "    test.append(cv2.imread(path + '/' + x))\n",
    "    labels.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "617f8b88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83588\n",
      "83588\n"
     ]
    }
   ],
   "source": [
    "print(len(test))\n",
    "print(len(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c83f2c0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as pl\n",
    "from tensorflow.keras.preprocessing import image\n",
    "for i in range(0, len(test)):\n",
    "    test[i] = image.img_to_array(test[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "8e53310d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Bags(data, NumberOfInstaces):\n",
    "    Allbags = []\n",
    "    \n",
    "    counter = 0\n",
    "    count = 0\n",
    "    \n",
    "    x = True\n",
    "    \n",
    "    while x:\n",
    "        bags = []\n",
    "        for w in range (0, NumberOfInstaces):\n",
    "            bags.append(data[counter])\n",
    "            counter += 1\n",
    "\n",
    "        count += NumberOfInstaces\n",
    "        bags = np.array(bags)\n",
    "        Allbags.append(bags)\n",
    "        if(len(data) - count >= NumberOfInstaces):\n",
    "            x = True\n",
    "        else:\n",
    "            x = False\n",
    "    \n",
    "    return Allbags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "8620ce02",
   "metadata": {},
   "outputs": [],
   "source": [
    "def BagsLabels(data, labels, positiveClass, NumberOfInstaces):\n",
    "    Allbags = []\n",
    "    bag_labels = []\n",
    "    \n",
    "    counter = 0\n",
    "    count = 0\n",
    "    \n",
    "    x = True\n",
    "    \n",
    "    while x:\n",
    "        label = 0\n",
    "        bags = []\n",
    "        for w in range (0, NumberOfInstaces):\n",
    "            bags.append(data[counter])\n",
    "            \n",
    "            if labels[counter] == 1:\n",
    "                label = positiveClass\n",
    "            \n",
    "            counter += 1\n",
    "\n",
    "        count += NumberOfInstaces\n",
    "        bags = np.array(bags)\n",
    "        Allbags.append(bags)\n",
    "        bag_labels.append(label)\n",
    "        if(len(data) - count >= NumberOfInstaces):\n",
    "            x = True\n",
    "        else:\n",
    "            x = False\n",
    "    \n",
    "    return bag_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "839dd99d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(83588, 64, 64, 3)\n"
     ]
    }
   ],
   "source": [
    "test = np.array(test)\n",
    "print(test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "7cf4c972",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83588\n",
      "0\n",
      "0\n",
      "400\n",
      "400\n",
      "800\n",
      "800\n",
      "1200\n",
      "1200\n",
      "1600\n",
      "1600\n",
      "2000\n",
      "2000\n",
      "2400\n",
      "2400\n",
      "2800\n",
      "2800\n",
      "3200\n",
      "3200\n",
      "3600\n",
      "3600\n",
      "4000\n",
      "4000\n",
      "4400\n",
      "4400\n",
      "4800\n",
      "4800\n",
      "5200\n",
      "5200\n",
      "5600\n",
      "5600\n",
      "6000\n",
      "6000\n",
      "6400\n",
      "6400\n",
      "6800\n",
      "6800\n",
      "7200\n",
      "7200\n",
      "7600\n",
      "7600\n",
      "8000\n",
      "8000\n",
      "8400\n",
      "8400\n",
      "8800\n",
      "8800\n",
      "9200\n",
      "9200\n",
      "9600\n",
      "9600\n",
      "10000\n",
      "10000\n",
      "10400\n",
      "10400\n",
      "10800\n",
      "10800\n",
      "11200\n",
      "11200\n",
      "11600\n",
      "11600\n",
      "12000\n",
      "12000\n",
      "12400\n",
      "12400\n",
      "12800\n",
      "12800\n",
      "13200\n",
      "13200\n",
      "13600\n",
      "13600\n",
      "14000\n",
      "14000\n",
      "14400\n",
      "14400\n",
      "14800\n",
      "14800\n",
      "15200\n",
      "15200\n",
      "15600\n",
      "15600\n",
      "16000\n",
      "16000\n",
      "16400\n",
      "16400\n",
      "16800\n",
      "16800\n",
      "17200\n",
      "17200\n",
      "17600\n",
      "17600\n",
      "18000\n",
      "18000\n",
      "18400\n",
      "18400\n",
      "18800\n",
      "18800\n",
      "19200\n",
      "19200\n",
      "19600\n",
      "19600\n",
      "20000\n",
      "20000\n",
      "20400\n",
      "20400\n",
      "20800\n",
      "20800\n",
      "21200\n",
      "21200\n",
      "21600\n",
      "21600\n",
      "22000\n",
      "22000\n",
      "22400\n",
      "22400\n",
      "22800\n",
      "22800\n",
      "23200\n",
      "23200\n",
      "23600\n",
      "23600\n",
      "24000\n",
      "24000\n",
      "24400\n",
      "24400\n",
      "24800\n",
      "24800\n",
      "25200\n",
      "25200\n",
      "25600\n",
      "25600\n",
      "26000\n",
      "26000\n",
      "26400\n",
      "26400\n",
      "26800\n",
      "26800\n",
      "27200\n",
      "27200\n",
      "27600\n",
      "27600\n",
      "28000\n",
      "28000\n",
      "28400\n",
      "28400\n",
      "28800\n",
      "28800\n",
      "29200\n",
      "29200\n",
      "29600\n",
      "29600\n",
      "30000\n",
      "30000\n",
      "30400\n",
      "30400\n",
      "30800\n",
      "30800\n",
      "31200\n",
      "31200\n",
      "31600\n",
      "31600\n",
      "32000\n",
      "32000\n",
      "32400\n",
      "32400\n",
      "32800\n",
      "32800\n",
      "33200\n",
      "33200\n",
      "33600\n",
      "33600\n",
      "34000\n",
      "34000\n",
      "34400\n",
      "34400\n",
      "34800\n",
      "34800\n",
      "35200\n",
      "35200\n",
      "35600\n",
      "35600\n",
      "36000\n",
      "36000\n",
      "36400\n",
      "36400\n",
      "36800\n",
      "36800\n",
      "37200\n",
      "37200\n",
      "37600\n",
      "37600\n",
      "38000\n",
      "38000\n",
      "38400\n",
      "38400\n",
      "38800\n",
      "38800\n",
      "39200\n",
      "39200\n",
      "39600\n",
      "39600\n",
      "40000\n",
      "40000\n",
      "40400\n",
      "40400\n",
      "40800\n",
      "40800\n",
      "41200\n",
      "41200\n",
      "41600\n",
      "41600\n",
      "42000\n",
      "42000\n",
      "42400\n",
      "42400\n",
      "42800\n",
      "42800\n",
      "43200\n",
      "43200\n",
      "43600\n",
      "43600\n",
      "44000\n",
      "44000\n",
      "44400\n",
      "44400\n",
      "44800\n",
      "44800\n",
      "45200\n",
      "45200\n",
      "45600\n",
      "45600\n",
      "46000\n",
      "46000\n",
      "46400\n",
      "46400\n",
      "46800\n",
      "46800\n",
      "47200\n",
      "47200\n",
      "47600\n",
      "47600\n",
      "48000\n",
      "48000\n",
      "48400\n",
      "48400\n",
      "48800\n",
      "48800\n",
      "49200\n",
      "49200\n",
      "49600\n",
      "49600\n",
      "50000\n",
      "50000\n",
      "50400\n",
      "50400\n",
      "50800\n",
      "50800\n",
      "51200\n",
      "51200\n",
      "51600\n",
      "51600\n",
      "52000\n",
      "52000\n",
      "52400\n",
      "52400\n",
      "52800\n",
      "52800\n",
      "53200\n",
      "53200\n",
      "53600\n",
      "53600\n",
      "54000\n",
      "54000\n",
      "54400\n",
      "54400\n",
      "54800\n",
      "54800\n",
      "55200\n",
      "55200\n",
      "55600\n",
      "55600\n",
      "56000\n",
      "56000\n",
      "56400\n",
      "56400\n",
      "56800\n",
      "56800\n",
      "57200\n",
      "57200\n",
      "57600\n",
      "57600\n",
      "58000\n",
      "58000\n",
      "58400\n",
      "58400\n",
      "58800\n",
      "58800\n",
      "59200\n",
      "59200\n",
      "59600\n",
      "59600\n",
      "60000\n",
      "60000\n",
      "60400\n",
      "60400\n",
      "60800\n",
      "60800\n",
      "61200\n",
      "61200\n",
      "61600\n",
      "61600\n",
      "62000\n",
      "62000\n",
      "62400\n",
      "62400\n",
      "62800\n",
      "62800\n",
      "63200\n",
      "63200\n",
      "63600\n",
      "63600\n",
      "64000\n",
      "64000\n",
      "64400\n",
      "64400\n",
      "64800\n",
      "64800\n",
      "65200\n",
      "65200\n",
      "65600\n",
      "65600\n",
      "66000\n",
      "66000\n",
      "66400\n",
      "66400\n",
      "66800\n",
      "66800\n",
      "67200\n",
      "67200\n",
      "67600\n",
      "67600\n",
      "68000\n",
      "68000\n",
      "68400\n",
      "68400\n",
      "68800\n",
      "68800\n",
      "69200\n",
      "69200\n",
      "69600\n",
      "69600\n",
      "70000\n",
      "70000\n",
      "70400\n",
      "70400\n",
      "70800\n",
      "70800\n",
      "71200\n",
      "71200\n",
      "71600\n",
      "71600\n",
      "72000\n",
      "72000\n",
      "72400\n",
      "72400\n",
      "72800\n",
      "72800\n",
      "73200\n",
      "73200\n",
      "73600\n",
      "73600\n",
      "74000\n",
      "74000\n",
      "74400\n",
      "74400\n",
      "74800\n",
      "74800\n",
      "75200\n",
      "75200\n",
      "75600\n",
      "75600\n",
      "76000\n",
      "76000\n",
      "76400\n",
      "76400\n",
      "76800\n",
      "76800\n",
      "77200\n",
      "77200\n",
      "77600\n",
      "77600\n",
      "78000\n",
      "78000\n",
      "78400\n",
      "78400\n",
      "78800\n",
      "78800\n",
      "79200\n",
      "79200\n",
      "79600\n",
      "79600\n",
      "80000\n",
      "80000\n",
      "80400\n",
      "80400\n",
      "80800\n",
      "80800\n",
      "81200\n",
      "81200\n",
      "81600\n",
      "81600\n",
      "82000\n",
      "82000\n",
      "82400\n",
      "82400\n",
      "82800\n",
      "82800\n",
      "83200\n"
     ]
    }
   ],
   "source": [
    "testFinal = []\n",
    "labelsFinal = []\n",
    "i = 0\n",
    "print(len(test))\n",
    "while i < len(test): \n",
    "    print(i)\n",
    "    if i + 400 <= len(test):\n",
    "        print(i)\n",
    "        testFinal.append(Bags(test[i:i+400], 400))\n",
    "        labelsFinal.append(BagsLabels(test[i:i+400], labels[i:i+400], 1, 400))\n",
    "    i += 400"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "9ad591e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "208\n",
      "208\n"
     ]
    }
   ],
   "source": [
    "print(len(testFinal))\n",
    "print(len(labelsFinal))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "cce648e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(208, 1, 400, 64, 64, 3)\n",
      "float32\n"
     ]
    }
   ],
   "source": [
    "testFinal = np.array(testFinal)\n",
    "print(testFinal.shape)\n",
    "print(testFinal.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "7a1cf0fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.1819219  0.81807816]]\n",
      "1\n",
      "[[0.26350778 0.73649216]]\n",
      "1\n",
      "[[0.2633677 0.7366322]]\n",
      "1\n",
      "[[0.3062765 0.6937235]]\n",
      "1\n",
      "[[0.2163405 0.7836596]]\n",
      "1\n",
      "[[0.17907982 0.8209202 ]]\n",
      "1\n",
      "[[0.2512987 0.7487012]]\n",
      "1\n",
      "[[0.16094242 0.83905756]]\n",
      "1\n",
      "[[0.17061226 0.8293877 ]]\n",
      "1\n",
      "[[0.15387227 0.8461278 ]]\n",
      "1\n",
      "[[0.16108727 0.8389128 ]]\n",
      "1\n",
      "[[0.13235822 0.8676418 ]]\n",
      "1\n",
      "[[0.14324759 0.85675246]]\n",
      "1\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-47-baec779705f2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtestFinal\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mprediction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtestFinal\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprediction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprediction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/GraduationProject_CrimeDetection/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m    907\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    908\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 909\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    910\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    911\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mreset_metrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/GraduationProject_CrimeDetection/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, model, x, batch_size, verbose, steps, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m    460\u001b[0m     return self._model_iteration(\n\u001b[1;32m    461\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPREDICT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 462\u001b[0;31m         steps=steps, callbacks=callbacks, **kwargs)\n\u001b[0m\u001b[1;32m    463\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    464\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/GraduationProject_CrimeDetection/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36m_model_iteration\u001b[0;34m(self, model, mode, x, y, batch_size, verbose, sample_weight, steps, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m    442\u001b[0m               \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    443\u001b[0m               \u001b[0mtraining_context\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining_context\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 444\u001b[0;31m               total_epochs=1)\n\u001b[0m\u001b[1;32m    445\u001b[0m           \u001b[0mcbks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_logs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    446\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/GraduationProject_CrimeDetection/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mrun_one_epoch\u001b[0;34m(model, iterator, execution_function, dataset_size, batch_size, strategy, steps_per_epoch, num_samples, mode, training_context, total_epochs)\u001b[0m\n\u001b[1;32m    121\u001b[0m         step=step, mode=mode, size=current_batch_size) as batch_logs:\n\u001b[1;32m    122\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 123\u001b[0;31m         \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    124\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mStopIteration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m         \u001b[0;31m# TODO(kaftan): File bug about tf function and errors.OutOfRangeError?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/GraduationProject_CrimeDetection/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training_v2_utils.py\u001b[0m in \u001b[0;36mexecution_function\u001b[0;34m(input_fn)\u001b[0m\n\u001b[1;32m     84\u001b[0m     \u001b[0;31m# `numpy` translates Tensors to values in Eager mode.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m     return nest.map_structure(_non_none_constant_value,\n\u001b[0;32m---> 86\u001b[0;31m                               distributed_function(input_fn))\n\u001b[0m\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/GraduationProject_CrimeDetection/lib/python3.6/site-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 457\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    458\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_counter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcalled_without_tracing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/GraduationProject_CrimeDetection/lib/python3.6/site-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    492\u001b[0m       \u001b[0;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    493\u001b[0m       \u001b[0;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 494\u001b[0;31m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    495\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_created_variables\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    496\u001b[0m         raise ValueError(\"Creating variables on a non-first call to a function\"\n",
      "\u001b[0;32m~/.conda/envs/GraduationProject_CrimeDetection/lib/python3.6/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1821\u001b[0m     \u001b[0;34m\"\"\"Calls a graph function specialized to the inputs.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1822\u001b[0m     \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1823\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1824\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1825\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/GraduationProject_CrimeDetection/lib/python3.6/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   1139\u001b[0m          if isinstance(t, (ops.Tensor,\n\u001b[1;32m   1140\u001b[0m                            resource_variable_ops.BaseResourceVariable))),\n\u001b[0;32m-> 1141\u001b[0;31m         self.captured_inputs)\n\u001b[0m\u001b[1;32m   1142\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1143\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/GraduationProject_CrimeDetection/lib/python3.6/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1222\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1223\u001b[0m       flat_outputs = forward_function.call(\n\u001b[0;32m-> 1224\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager)\n\u001b[0m\u001b[1;32m   1225\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1226\u001b[0m       \u001b[0mgradient_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_delayed_rewrite_functions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregister\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/GraduationProject_CrimeDetection/lib/python3.6/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    509\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    510\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"executor_type\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexecutor_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"config_proto\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 511\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    512\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    513\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m~/.conda/envs/GraduationProject_CrimeDetection/lib/python3.6/site-packages/tensorflow_core/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tensorflow.TFE_Py_Execute(ctx._handle, device_name,\n\u001b[1;32m     60\u001b[0m                                                \u001b[0mop_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m                                                num_outputs)\n\u001b[0m\u001b[1;32m     62\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'\n",
    "from numpy import argmax\n",
    "\n",
    "FinalPredictions = []\n",
    "\n",
    "count_normal = 0\n",
    "count_Anomly = 0\n",
    "\n",
    "for i in range(len(testFinal)):\n",
    "    prediction = (model.predict(testFinal[i]))\n",
    "    print(prediction)\n",
    "    result = argmax(prediction)\n",
    "    FinalPredictions.append(result)\n",
    "    \n",
    "    if result == 0:\n",
    "        count_normal += 1\n",
    "    else:\n",
    "        count_Anomly += 1\n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02cf87cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(\"Nomral Predictions:\",count_normal)\n",
    "#print(\"Anomly Predictions:\",count_Anomly)\n",
    "print(len(FinalPredictions))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c8261f1d",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-3ae9565839ed>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/Users/kareemel-mallahy/Desktop/Graduation Project/Models/3DCNN-LSTM-BestPrediction.h5\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "model.save(\"/Users/kareemel-mallahy/Desktop/Graduation Project/Models/3DCNN-LSTM-BestPrediction.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a8ae34b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96       161\n",
      "           1       1.00      0.88      0.94       116\n",
      "\n",
      "    accuracy                           0.95       277\n",
      "   macro avg       0.96      0.94      0.95       277\n",
      "weighted avg       0.95      0.95      0.95       277\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import sklearn\n",
    "import sklearn.metrics as metrics\n",
    "from sklearn.metrics import accuracy_score\n",
    "report = metrics.classification_report(labelsFinal, FinalPredictions)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "79d9f336",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[161   0]\n",
      " [ 14 102]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "#Generate the confusion matrix\n",
    "cf_matrix = confusion_matrix(labelsFinal, FinalPredictions)\n",
    "print(cf_matrix)\n",
    "\n",
    "import seaborn as sns\n",
    "ax = sns.heatmap(cf_matrix, annot=True, cmap='Blues')\n",
    "ax.set_title('3D CNN - 2D LSTM  Hybrid Model');\n",
    "ax.set_xlabel('\\nPredicted Values')\n",
    "ax.set_ylabel('Actual Values ');\n",
    "## Ticket labels - List must be in alphabetical order\n",
    "ax.xaxis.set_ticklabels(['False','True'])\n",
    "ax.yaxis.set_ticklabels(['Normal','Crime'])\n",
    "## Display the visualization of the Confusion Matrix.\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b157de6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import imutils\n",
    "# make bounding box predictions on the input image\n",
    "preds = model.predict(testFinal[0])[0]\n",
    "(startX, startY) = preds\n",
    "# load the input image (in OpenCV format), resize it such that it\n",
    "# fits on our screen, and grab its dimensions\n",
    "imagePath = '/Users/kareemel-mallahy/Desktop/Graduation Project/DataSetFrames/Train/Arrest/Arrest002_x264_140.png'\n",
    "image = cv2.imread(imagePath)\n",
    "image = imutils.resize(image, width=600)\n",
    "(h, w) = image.shape[:2]\n",
    "# scale the predicted bounding box coordinates based on the image\n",
    "# dimensions\n",
    "startX = int(startX * w)\n",
    "startY = int(startY * h)\n",
    "endX = int(startX * w + 20)\n",
    "endY = int(startY * h + 20)\n",
    "# draw the predicted bounding box on the image\n",
    "cv2.rectangle(image, (startX, startY), (endX, endY),\n",
    "(0, 255, 0), 2)\n",
    "# show the output image\n",
    "cv2.imshow(\"Output\", image)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9437fc11",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
